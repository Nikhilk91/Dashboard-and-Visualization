{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab - 7\n",
    "\n",
    "#### Tableau: https://public.tableau.com/profile/nikhil.kaushik#!/vizhome/Book_12_0/Dashboard_1?publish=yes\n",
    "\n",
    "#### Purpose of Lab-3:\n",
    "Develop persuasive visualization for data breaches and its impact using stock prices as a parameter. This required data wrangling to read JSON symbols from Yahoo Query Tool to extract and clean stock price data of various companies from Yahoo Finance. \n",
    "\n",
    "**Technology Used:** Python in Jupyter notebook to extract stock data from Yahoo Finance. This extraction is done from JSON file and then based on Ticker values the stock prices for 40+ companies were picked.\n",
    "In this Lab, we made use of Fuzzy Wuzzy giving more insights of how we can do string matchin using it.\n",
    "\n",
    "\n",
    "#### Road map with future features/enhancements/features (For Lab-3):\n",
    "\n",
    "**1.**  The visual created in Lab-3 shows data for one particular company. This particular company could be an outlier, in turn can prove this visual a 'deceptive' one.\n",
    "\n",
    "**Improvement:** Add more details in the caption regarding why the particular company is chosen.\n",
    "\n",
    "**2.** The references are missing in the visual. Refrences add more value to the product.\n",
    "\n",
    "**Improvement:** Add references in the caption.\n",
    "\n",
    "\n",
    "**3.** The analysis is based just on the basis of stock prices and this could again be not a sufficient parameter to make the claim.\n",
    "\n",
    "**Improvement:** More parameters could be addded to this visualization. For instance, security breach could affect the market valuation of the company. So, market valuation could be used as one of the parameters too.\n",
    "\n",
    "**4.** The visual doesn't provide any data about how the overall market reacted in that particular year.\n",
    "\n",
    "**Improvement:** Adding information about how the overall market was reacting in that particular year also gives some sense of support to the claim. There could be a case when the drop in the stock price is due to the overall market crash and not because of the security breach. If the market reaction is mentioned in the visual, the user doesn't have to seacrch for this information in case of doubt.\n",
    "\n",
    "**5** The reaction of security breach could affect different companies differently. The companies which are more data centric such as banks would react highly to breaches.\n",
    "\n",
    "**Improvement:** The analysis could be based on different segments of companies. Segmenting data based on the category could help in resolving the issue. Financial firms may react to breaches completely differently when compared to IT companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import datetime as dt\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"Data_Assignment2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del Data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "def get_symbol(name):\n",
    "    url = \"http://d.yimg.com/autoc.finance.yahoo.com/autoc?query={}&region=1&lang=en\".format(name)\n",
    "\n",
    "    result = requests.get(url).json()\n",
    "    \n",
    "    for x in result['ResultSet']['Result']:\n",
    "        #if x['name'] == name :\n",
    "            #if (x['exchDisp']=='NYSE'or x['exchDisp']=='NASDAQ'):\n",
    "                #if x['typeDisp']=='Equity':\n",
    "           # n = fuzz.token_set_ratio(name, x['name'])\n",
    "            #if n >65:\n",
    "                    return x['symbol']\n",
    "        \n",
    "##company = get_symbol(\"twitter\")\n",
    "##print(company)\n",
    "ticker=[]\n",
    "cmp_name = Data.ENTITY\n",
    "##for  xyz in cmp_name:\n",
    "    ##ticker = get_symbol(xyz)\n",
    "    ##print(ticker)\n",
    "    \n",
    "for  xyz in cmp_name:\n",
    "    ticker.append(get_symbol(xyz))\n",
    "    \n",
    "    \n",
    "#print(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'AOL-U.TI', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: None, replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'CIT-U.TI', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: '^UMIAMIFL', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'JPM-PB', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'GB00B1Z54R10.L', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: '603330.SS', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'KCT.V', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'K55306BA2822.KS', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'NMBS.KL', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'JAPSY', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'CPWFF8.EX', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'FLINGX', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/Nikhil/anaconda/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'VKTX', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime(2013,1,1)\n",
    "end = dt.datetime(2014,1,1)\n",
    "data_source = 'yahoo'\n",
    "panel_data = pdr.DataReader(ticker, data_source, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The index in this DataFrame is the major index of the panel_data.\n",
    "close = panel_data.ix['Close']\n",
    "\n",
    "start_dt = dt.datetime(2013,1,1)\n",
    "end_dt = dt.datetime(2013,12,31)\n",
    "\n",
    "# Getting all weekdays between 01/01/2004 and 12/31/2016\n",
    "all_weekdays = pd.date_range(start=start_dt, end=end_dt, freq='B')\n",
    "\n",
    "# How do we align the existing prices in adj_close with our new set of dates?\n",
    "# All we need to do is reindex close using all_weekdays as the new index\n",
    "close = close.reindex(all_weekdays)\n",
    "\n",
    "close.head(10)\n",
    "close = close.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close.to_csv('Lab3_Finance.csv', index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ticker = pd.DataFrame(ticker) \n",
    "data_ticker['Ticker_Symbol'] = pd.Series(ticker, index=data_ticker.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data['Ticker_symbol']= data_ticker['Ticker_Symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop empty columns(axis=1 for columns and axis=0 for rows; \n",
    "#how='all' to drop if all values are nan and how='any' to drop if any value is nan)\n",
    "Data = Data.dropna(axis=0,how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data.to_csv('Lab3_Finance1.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close = close.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close.to_csv('Lab3_Finance.csv', index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_df= pd.DataFrame(columns=['Symbol','Date','Price'])\n",
    "k =0\n",
    "for i in range(len(close)) : \n",
    "    ts = close.index[i]\n",
    "    for j in range(len(close.iloc[i])): \n",
    "        time_frame = pd.to_datetime(str(close.columns.values[j]))\n",
    "        date = time_frame.strftime('%Y-%m-%d')\n",
    "        r_df.loc[k]=( ts,  date , close.iloc[i][j])\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_df.to_csv('Stock.csv', index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. The intermediate version show data for different quarter, year, dates\n",
    "2. This version is difficult to und"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
