{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Session 8 : MSIS Student Dashboard (Redesign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This session is about redesigning the dashboard created for prospective students in Lab-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fetching data from different sites using 'Beautiful Soup'.\n",
    "2. Site 1 : https://www.scu.edu/business/ms-information-systems/prospective-students/class-profile/\n",
    "\n",
    "This data will give us insight about the following:\n",
    "Women, Average age, Multilingual, Average undergraduate GPA, Average GMAT, Average GRE  308, % holding graduate degrees  20%, Average work experience, Employed at time of admission, Selected hiring companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('max_columns', 120)\n",
    "pd.set_option('max_colwidth', 5000)\n",
    "pd.set_option('max_rows', 300)\n",
    "import pandas as pd\n",
    "import numpy as nm\n",
    "import matplotlib as mp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import seaborn as sns\n",
    "import pandas_datareader as pdr\n",
    "from pandas_datareader.data import Options\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"https://www.scu.edu/business/ms-information-systems/prospective-students/class-profile/\")\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "#soup.prettify(formatter=lambda s: s.replace(u'\\xa0', ' '))\n",
    "#print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = soup.find_all(\"div\", {\"class\":\"one-column news module\"})\n",
    "#demog.soup.prettify(formatter=lambda s: s.replace(u'\\xa0', ' '))\n",
    "#nonBreakSpace = u'\\xa0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_p=[]\n",
    "myiter = iter(range(0, 3))\n",
    "for i in myiter:\n",
    "    for item in soup[i]:\n",
    "        try:   \n",
    "            acc_rows = item.find_all('p')\n",
    "            #print(acc_rows)\n",
    "            j =0\n",
    "            for p in acc_rows:\n",
    "            #print (item)\n",
    "                #print (acc_rows)\n",
    "                #myitr = iter(range(0, 3))\n",
    "                #for i in myitr:\n",
    "                    text_p.append((acc_rows[j].text).replace('\\xa0', ' '))\n",
    "                    j = j+1\n",
    "                #print (item.get_text())\n",
    "                #print (item.get_text())\n",
    "            #print (item.next_sibling.item.get_text())\n",
    "        except:\n",
    "            print(\"no tbody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#with open ('SCUMSIS_Class_Profile.csv','wb') as file:\n",
    "#   writer=csv.writer(file)\n",
    "#   for row in demog:\n",
    "#      writer.writerow(row)\n",
    "\n",
    "f= open('SCUMSIS_Class_Profile.csv', 'w')\n",
    "csv_writer = csv.writer(f)\n",
    "for i in text_p:\n",
    "    csv_writer.writerow([i])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time taken to collect the data took a lot of time.\n",
    "1. It took more time to learn about using the beautiful soup.\n",
    "2. The data had issues, the spaces were coming as &nbsp. I had to look for the code and remove them.\n",
    "3. Getting data from different paragraphs as a different text was the next challenge. Spent long time in figuring out how to loop it.\n",
    "4. Converting the data into CSV file was the next challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source 2\n",
    "Source Link: https://www.payscale.com/research/US/Degree=Master_of_Information_Science_(MIS)/Salary\n",
    "\n",
    "This will give data about the salary bracket for MIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = requests.get(\"https://www.payscale.com/research/US/Degree=Master_of_Information_Science_(MIS)/Salary\")\n",
    "html3 = response3.content\n",
    "soup = BeautifulSoup(html3, 'html.parser')\n",
    "#soup.prettify(formatter=lambda s: s.replace(u'\\xa0', ' '))\n",
    "#print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pay = soup.find_all(\"div\", {\"class\":\"bar-chart-bootstrap\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pay1=[]\n",
    "for item in pay:\n",
    "    pay1.append(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source 3\n",
    "Source Link: http://www.acceptancerate.com/california\n",
    "\n",
    "This gives the different acceptance rate for different universities in California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response3 = requests.get(\"http://www.acceptancerate.com/california\")\n",
    "html3 = response3.content\n",
    "soup = BeautifulSoup(html3, 'html.parser')\n",
    "#soup.prettify(formatter=lambda s: s.replace(u'\\xa0', ' '))\n",
    "#print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_rate= soup.find_all(\"table\", \"table table-hover table-condensed listing_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc=[]\n",
    "\n",
    "for mytable in acc_rate:\n",
    "    acc_body = mytable.find('tbody')\n",
    "    try:\n",
    "        acc_rows = acc_body.find_all('tr')\n",
    "        for tr in acc_rows:\n",
    "            acc_cols = tr.find_all('td')\n",
    "            name = acc_cols[1].text\n",
    "            applicants = acc_cols[2].string\n",
    "            admitted = acc_cols[3].string\n",
    "            accept_rate = acc_cols[4].string\n",
    "            record = (name, applicants, admitted, accept_rate)\n",
    "    except:\n",
    "        print(\"no tbody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#with open ('SCUMSIS_Class_Profile.csv','wb') as file:\n",
    "#   writer=csv.writer(file)\n",
    "#   for row in demog:\n",
    "#      writer.writerow(row)\n",
    "\n",
    "f= open('acceptance.csv', 'a')\n",
    "csv_writer = csv.writer(f)\n",
    "for i in record:\n",
    "    csv_writer.writerow(i)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source\n",
    "Source Link: http://higheredublog.com/top-universities-for-ms-in-mis-in-usa/\n",
    "\n",
    "This gives the data for top universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://higheredublog.com/top-universities-for-ms-in-mis-in-usa/'\n",
    "data = pd.read_html(url, header = 0)\n",
    "\n",
    "data1 = data[0]\n",
    "data1.head()\n",
    "\n",
    "data1.columns = ['RANKING', 'UNIVERSITY', 'PROGRAM']\n",
    "\n",
    "df = pd.DataFrame(data1)\n",
    "\n",
    "df.to_csv('univ_ranking.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data I have picked is from linkedIn. I tried working on different datasets from learning perspective. In the end I created an excel from the LinkedIn.\n",
    "Source: https://www.linkedin.com/school/10458916/alumni/?filterByOption=graduated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
